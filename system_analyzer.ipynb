{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c60f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f7e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"app_data.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d8c5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE      TIME APPLICATION\n",
      "0  12-06-2023  12:05:01    nautilus\n",
      "1  12-06-2023  12:05:03    nautilus\n",
      "2  12-06-2023  12:05:04       gedit\n",
      "3  12-06-2023  12:05:05       gedit\n",
      "4  12-06-2023  12:05:06       gedit\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c077b",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b7266b-6475-42ab-b095-b2b74beccdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nautilus\n",
      "nautilus\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,2])\n",
    "print(df.loc[0,'APPLICATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a211404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE START_TIME  END_TIME  USAGE   APPLICATION\n",
      "0  12-06-2023   12:05:01  12:05:03    2.0      nautilus\n",
      "1  12-06-2023   12:05:03  12:05:07    1.0         gedit\n",
      "2  12-06-2023   12:05:07  12:05:08    1.0      nautilus\n",
      "3  12-06-2023   12:05:08  12:05:10    1.0           gjs\n",
      "4  12-06-2023   12:05:10  12:05:17    1.0  sublime_text\n"
     ]
    }
   ],
   "source": [
    "\t\t\"\"\"Converting the data set into the fomat\n",
    "\t\t   DATE        START_TIME     END_TIME USAGE   APPLICATION\n",
    "\t\t   11-01-2022  11:49:42       11:50:33    52   thunar     \"\"\"\n",
    "\n",
    "cleaned_app_data=\"clean_app_data.csv\"    #name of file in which w'll store clean data\n",
    "new_df = pd.DataFrame(columns=[\"DATE\", \"START_TIME\", \"END_TIME\",\"USAGE\",\"APPLICATION\"])\n",
    "\n",
    "def time_difference(time1, time2):\n",
    "    format_str = '%H:%M:%S'\n",
    "    time_obj1 = datetime.strptime(time1, format_str)\n",
    "    time_obj2 = datetime.strptime(time2, format_str)\n",
    "    time_diff = time_obj2 - time_obj1\n",
    "    return time_diff.total_seconds()\n",
    "start_index=0\n",
    "last_row_index = df.index[-1]\n",
    "# print(last_row_index)\n",
    "# try:\n",
    "#     for index, row in df.iterrows():\n",
    "#         if (df.iloc[index,2]==df.iloc[(index+1),2]):\n",
    "#             time_diff= time_difference(df.iloc[index,1], df.iloc[(index+1),1])\n",
    "#             if time_diff < 5 and (df.iloc[index,0]==df.iloc[(index+1),0]):\n",
    "#                 pass\n",
    "#         else:\n",
    "#             new_df.loc[len(new_df)] = [df.iloc[index,0],df.iloc[start_index,1],df.iloc[index,1],time_diff,df.iloc[index,2]]\n",
    "#             start_index=index\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# DATE      TIME APPLICATION\n",
    "try:\n",
    "    for index, row in df.iterrows():\n",
    "        if (row[\"APPLICATION\"]==df.iloc[(index+1),2]):\n",
    "            time_diff= time_difference(row[\"TIME\"], df.iloc[(index+1),1])\n",
    "            if time_diff < 5 and (row[\"DATE\"]==df.iloc[(index+1),0]):\n",
    "                pass\n",
    "        else:\n",
    "            new_df.loc[len(new_df)] = [row[\"DATE\"],df.iloc[start_index,1],row[\"TIME\"],time_diff,row[\"APPLICATION\"]]\n",
    "            start_index=index\n",
    "except:\n",
    "    pass\n",
    "print(new_df.head())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2f16077-11b4-48cf-be3b-dd8e2b8d77b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(h2) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3600\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(m2) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(s2)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t2 \u001b[38;5;241m-\u001b[39m t1\n\u001b[0;32m---> 25\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mfind_consecutive_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAPPLICATION\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m, in \u001b[0;36mfind_consecutive_rows\u001b[0;34m(df, application, time_threshold)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPPLICATION\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m application:\n\u001b[0;32m----> 6\u001b[0m         \u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[start_index, \u001b[38;5;241m1\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m\"\u001b[39m], time_difference(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m\"\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[start_index, \u001b[38;5;241m1\u001b[39m]), row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPPLICATION\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      7\u001b[0m         start_index \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m time_difference(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m\"\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[start_index, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m time_threshold \u001b[38;5;129;01mand\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start_index, \u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 849\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1825\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1825\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1829\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:2158\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[1;32m   2156\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[1;32m   2157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 2158\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2160\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "def find_consecutive_rows(df, application, time_threshold):\n",
    "    new_df = pd.DataFrame(columns=[\"DATE\", \"TIME\", \"DIFF\", \"APPLICATION\"])\n",
    "    start_index = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"APPLICATION\"] != application:\n",
    "            new_df.loc[len(new_df)] = [row[\"DATE\"], df.iloc[start_index, 1], row[\"TIME\"], time_difference(row[\"TIME\"], df.iloc[start_index, 1]), row[\"APPLICATION\"]]\n",
    "            start_index = index\n",
    "        elif time_difference(row[\"TIME\"], df.iloc[start_index, 1]) <= time_threshold and row[\"DATE\"] == df.iloc[start_index, 0]:\n",
    "            pass\n",
    "        else:\n",
    "            new_df.loc[len(new_df)] = [row[\"DATE\"], df.iloc[start_index, 1], row[\"TIME\"], time_difference(row[\"TIME\"], df.iloc[start_index, 1]), row[\"APPLICATION\"]]\n",
    "            start_index = index\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def time_difference(time1, time2):\n",
    "    h1, m1, s1 = time1.split(\":\")\n",
    "    h2, m2, s2 = time2.split(\":\")\n",
    "\n",
    "    t1 = int(h1) * 3600 + int(m1) * 60 + int(s1)\n",
    "    t2 = int(h2) * 3600 + int(m2) * 60 + int(s2)\n",
    "\n",
    "    return t2 - t1\n",
    "\n",
    "new_df = find_consecutive_rows(df, \"APPLICATION\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5e560",
   "metadata": {},
   "source": [
    "# Show the pie chart of the current day computer usage in pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82225bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
